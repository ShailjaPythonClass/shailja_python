{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server_name = \"\"\n",
    "junk_table = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've been waiting for this for 2 months, pulling data directly into python.  So of course I have no slides ready.\n",
    "\n",
    "To pull data directly from SQL, we use the python database conenctor, pyodbc.  Since you all now have it (yay), let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "con = pyodbc.connect('DSN={}'.format(server_name))\n",
    "query = \"SELECT * FROM {}\".format(junk_table)\n",
    "\n",
    "print query\n",
    "res = con.execute(query)\n",
    "print res.fetchall()[:5]\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That code imports the python database connector library, establishes a connection to our Fox database, executes a simple query, prints its result, and closes the connection.\n",
    "\n",
    "The line that won't work without some configuration is the connect line: I configure pyodbc to use my Windows credentials so that I don't have to store my password in python code.  You do this by clicking on the windows start button and typing \"Data Sources (ODBC)\" and opening that program once windows finds it.  \n",
    "\n",
    "In the User DSN tab click Add... ==> select SQL Server Native Client 11.0 ==> Finish\n",
    "On the next screen type the server's name [server for this lesson] in all 3 boxes (Name / Description / Server).\n",
    "Click next until you see a finish button, and then \"Test Data Source\" if somehow this didn't work, google / ask a classmate after.\n",
    "\n",
    "Try again after configuration, this time putting the connection object in a with block so that it closes once we're done with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM {}\".format(junk_table)\n",
    "\n",
    "with pyodbc.connect('DSN={}'.format(server_name)) as con:\n",
    "    res = con.execute(query)\n",
    "    print res.fetchall()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently, you want to save results to a file rather than just display them on your python terminal.  We can write a unicode csv easily with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ensure we have an output directory\n",
    "import os\n",
    "try:\n",
    "    os.mkdir('output')\n",
    "except WindowsError:\n",
    "    pass\n",
    "\n",
    "import unicodecsv\n",
    "query = \"SELECT * FROM {}\".format(junk_table)\n",
    "\n",
    "with pyodbc.connect('DSN={}'.format(server_name)) as con:\n",
    "    res = con.execute(query)\n",
    "    with open('output/out.csv', 'wb') as outf:\n",
    "        writer = unicodecsv.writer(outf)\n",
    "        # Write header information for each row\n",
    "        writer.writerow([x[0] for x in res.description])\n",
    "        for row in res:\n",
    "            writer.writerow(row)\n",
    "print \"CSV file written\"\n",
    "\n",
    "df = pd.read_csv('output/out.csv')\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have a file \"output/out.csv\"  If you would rather have a more useful data format for the query results, like a pandas dataframe, or an excel file, we can do that too (!).\n",
    "\n",
    "For excel files be careful that the file isn't open in excel when you try to have python write it: Excel locks the file for writing when it's open and is a giant pain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ensure we have an output directory\n",
    "import os\n",
    "try:\n",
    "    os.mkdir('output')\n",
    "except WindowsError:\n",
    "    pass\n",
    "\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "query = \"SELECT * FROM {}\".format(junk_table)\n",
    "\n",
    "with pyodbc.connect('DSN={}'.format(server_name)) as con:\n",
    "    df = pd.read_sql(query, con)\n",
    "\n",
    "df.to_excel('output/out.xlsx', 'query_sheet', index=False)\n",
    "pickle.dump(df, open('output/out.df.pkl', 'wb'))\n",
    "\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only can we write a single dataframe to a single excel sheet, but we can write multiple dataframes to the same excel sheet, all using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('output/multi_sheets.xlsx')\n",
    "for i in range(5):\n",
    "    temp = df.copy()\n",
    "    if i != 0:\n",
    "        temp[temp.columns[i]] = i\n",
    "    temp.to_excel(writer, 'sheet{}'.format(i), index=False)\n",
    "    del temp\n",
    "writer.save()\n",
    "\n",
    "print \"Big excel file written\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python-class]",
   "language": "python",
   "name": "conda-env-python-class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
