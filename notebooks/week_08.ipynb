{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week, we anonomized Shailja's dataset that was pulled directly from SQL.  Engineering hasn't installed pyodbc on your systems, so a direct SQL pull still isn't going to happen, but we have 2902 anonomyzed rows to play with.\n",
    "\n",
    "Our goals this week are to go over: \n",
    "pandas file i/o, vs load, vs pickle\n",
    "row functions\n",
    "looping over the rows of a dataframe\n",
    "the apply function\n",
    "\n",
    "Plotting if we have time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "datecols = ['new_eta', 'original_eta', 'actual_receive_date']\n",
    "datapath = '../status_analysis/data/'\n",
    "df = pd.read_csv(datapath + 'anon.csv', parse_dates=datecols)\n",
    "\n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the only way we've been loading files: csv in pandas.  We could have loaded this file as text with the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapath = '../status_analysis/data/'\n",
    "\n",
    "with open(datapath + 'anon.csv', 'r') as inf:\n",
    "    file_text = inf.readlines()\n",
    "    \n",
    "for line in file_text[:10]:\n",
    "    print line,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the underlying text in the comma separated values file, which you can verify by opening anon.csv with notebook rather than Excel.  Focusing on the open command:  we put the open(filename, mode) command in a with block so that the resource is closed once we finish the loop where we need that resource.  This is good practice in general, especially with SQL resources.\n",
    "\n",
    "We can also use open in cojunction with one of python's best libraries, pickle, to store any python object in a binary (fast but human unreadable) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "datapath = '../status_analysis/data/'\n",
    "pickle.dump(df, open(datapath + 'binary.pkl', 'wb'))\n",
    "loaded_df = pickle.load(open(datapath + 'binary.pkl', 'rb'))\n",
    "len(loaded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can store multiple variables in a single pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "datapath = '../status_analysis/data/'\n",
    "\n",
    "a_list = [1,2,3]\n",
    "a_tuple = ['a', 6, []]\n",
    "a_dict = {'a':1, 'b':2, 'c':3}\n",
    "\n",
    "pickle.dump((a_list, a_tuple, a_dict), open(datapath + 'multiout.pkl', 'wb'))\n",
    "\n",
    "b_list, b_tuple, b_dict = pickle.load(open(datapath + 'multiout.pkl', 'rb'))\n",
    "print b_list, b_tuple, b_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our dataframe: we can perform columnwise functions easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.status_code.min()\n",
    "print df.status_code.sum()\n",
    "\n",
    "# This is how one performs a sumif\n",
    "print df.loc[df.is_escalating == True].status_code.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform a loop over every row and calculate something.  We shouldn't because it's slow, but the functionality exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['derived'] = -1\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    df.loc[i, 'derived'] = row['actual_receive_date'] - row['original_eta']\n",
    "print df['derived'].max(), df['derived'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a simple task: for all ids, see how many of them have more than one touchpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "more_than_one = []\n",
    "\n",
    "for id in df['id'].unique():\n",
    "    sub = df[df['id'] == id]\n",
    "    if len(sub) > 1:\n",
    "        more_than_one.append(id)\n",
    "print len(more_than_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this elegantly with a pandas apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def has_more_than_one(group):\n",
    "    if len(group) > 1:\n",
    "        return True\n",
    "    return None\n",
    "\n",
    "results = df.groupby('id').apply(has_more_than_one)\n",
    "print results.dropna().head()\n",
    "print type(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this returned a series.  If you want more than one column returned from your apply funciton, it's pretty easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def two_outputs(group):\n",
    "    if len(group) > 1:\n",
    "        return pd.Series({'multi_touch': True, 'n_contacts': len(group)})\n",
    "    return pd.Series({'multi_touch': None, 'n_contacts': len(group)})\n",
    "\n",
    "results = df.groupby('id').apply(two_outputs)\n",
    "print results.dropna().head()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python-class]",
   "language": "python",
   "name": "conda-env-python-class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
